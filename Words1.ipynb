{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Words1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nlaimr/Intro-Deep-Learning-Notebooks/blob/master/Words1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b91yqSIO5cZ-"
      },
      "source": [
        "%matplotlib inline\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "import urllib\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw9Mc8pd5mf3"
      },
      "source": [
        "glove_zip_file = \"glove.6B.zip\"\r\n",
        "glove_vectors_file = \"glove.6B.50d.txt\"\r\n",
        "\r\n",
        "snli_zip_file = \"snli_1.0.zip\"\r\n",
        "snli_dev_file = \"snli_1.0_dev.txt\"\r\n",
        "snli_full_dataset_file = \"snli_1.0_train.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDzNRKQi5sMk"
      },
      "source": [
        "from six.moves.urllib.request import urlretrieve\r\n",
        "#Takes ~15 minutes\r\n",
        "#large file - 862 MB\r\n",
        "if (not os.path.isfile(glove_zip_file) and\r\n",
        "    not os.path.isfile(glove_vectors_file)):\r\n",
        "    urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \r\n",
        "                 glove_zip_file)\r\n",
        "\r\n",
        "#medium-sized file - 94.6 MB\r\n",
        "if (not os.path.isfile(snli_zip_file) and\r\n",
        "    not os.path.isfile(snli_dev_file)):\r\n",
        "    urlretrieve (\"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\", \r\n",
        "                 snli_zip_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4FU1--D5utH"
      },
      "source": [
        "def unzip_single_file(zip_file_name, output_file_name):\r\n",
        "    \"\"\"\r\n",
        "        If the outFile is already created, don't recreate\r\n",
        "        If the outFile does not exist, create it from the zipFile\r\n",
        "    \"\"\"\r\n",
        "    if not os.path.isfile(output_file_name):\r\n",
        "        with open(output_file_name, 'wb') as out_file:\r\n",
        "            with zipfile.ZipFile(zip_file_name) as zipped:\r\n",
        "                for info in zipped.infolist():\r\n",
        "                    if output_file_name in info.filename:\r\n",
        "                        with zipped.open(info) as requested_file:\r\n",
        "                            out_file.write(requested_file.read())\r\n",
        "                            return\r\n",
        "\r\n",
        "unzip_single_file(glove_zip_file, glove_vectors_file)\r\n",
        "unzip_single_file(snli_zip_file, snli_dev_file)\r\n",
        "# unzip_single_file(snli_zip_file, snli_full_dataset_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3O3ISVL5xGR"
      },
      "source": [
        "glove_wordmap = {}\r\n",
        "with open(glove_vectors_file, \"r\") as glove:\r\n",
        "    for line in glove:\r\n",
        "        name, vector = tuple(line.split(\" \", 1))\r\n",
        "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc4-TFWy50h8"
      },
      "source": [
        "def sentence2sequence(sentence):\r\n",
        "    \"\"\"\r\n",
        "     \r\n",
        "    - Turns an input sentence into an (n,d) matrix, \r\n",
        "        where n is the number of tokens in the sentence\r\n",
        "        and d is the number of dimensions each word vector has.\r\n",
        "    \r\n",
        "      Tensorflow doesn't need to be used here, as simply\r\n",
        "      turning the sentence into a sequence based off our \r\n",
        "      mapping does not need the computational power that\r\n",
        "      Tensorflow provides. Normal Python suffices for this task.\r\n",
        "    \"\"\"\r\n",
        "    tokens = sentence.lower().split(\" \")\r\n",
        "    rows = []\r\n",
        "    words = []\r\n",
        "    #Greedy search for tokens\r\n",
        "    for token in tokens:\r\n",
        "        i = len(token)\r\n",
        "        while len(token) > 0 and i > 0:\r\n",
        "            word = token[:i]\r\n",
        "            if word in glove_wordmap:\r\n",
        "                rows.append(glove_wordmap[word])\r\n",
        "                words.append(word)\r\n",
        "                token = token[i:]\r\n",
        "                i = len(token)\r\n",
        "            else:\r\n",
        "                i = i-1\r\n",
        "    return rows, words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "gyTTaHoL6onU",
        "outputId": "3ae01430-b093-41cf-9a2f-1ba067180252"
      },
      "source": [
        "def visualize(sentence):\r\n",
        "    rows, words = sentence2sequence(sentence)\r\n",
        "    mat = np.vstack(rows)\r\n",
        "    \r\n",
        "    fig = plt.figure()\r\n",
        "    ax = fig.add_subplot(111)\r\n",
        "    shown = ax.matshow(mat, aspect=\"auto\")\r\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "    fig.colorbar(shown)\r\n",
        "    \r\n",
        "    ax.set_yticklabels([\"\"]+words)\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "visualize(\"The quick brown fox jumped over the lazy dog.\")\r\n",
        "visualize(\"The pretty flowers shone in the sunlight.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2b6ASFQ7hai"
      },
      "source": [
        "#Constants setup\r\n",
        "max_hypothesis_length, max_evidence_length = 30, 30\r\n",
        "batch_size, vector_size, hidden_size = 128, 50, 64\r\n",
        "\r\n",
        "lstm_size = hidden_size\r\n",
        "\r\n",
        "weight_decay = 0.0001\r\n",
        "\r\n",
        "learning_rate = 1\r\n",
        "\r\n",
        "input_p, output_p = 0.5, 0.5\r\n",
        "\r\n",
        "training_iterations_count = 100000\r\n",
        "\r\n",
        "display_step = 10\r\n",
        "\r\n",
        "def score_setup(row):\r\n",
        "    convert_dict = {\r\n",
        "      'entailment': 0,\r\n",
        "      'neutral': 1,\r\n",
        "      'contradiction': 2\r\n",
        "    }\r\n",
        "    score = np.zeros((3,))\r\n",
        "    for x in range(1,6):\r\n",
        "        tag = row[\"label\"+str(x)]\r\n",
        "        if tag in convert_dict: score[convert_dict[tag]] += 1\r\n",
        "    return score / (1.0*np.sum(score))\r\n",
        "\r\n",
        "def fit_to_size(matrix, shape):\r\n",
        "    res = np.zeros(shape)\r\n",
        "    slices = [slice(0,min(dim,shape[e])) for e, dim in enumerate(matrix.shape)]\r\n",
        "    res[slices] = matrix[slices]\r\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLA0N2bt7kQw",
        "outputId": "d80ad926-da1b-43fb-c572-8fff271580dc"
      },
      "source": [
        "def split_data_into_scores():\r\n",
        "    import csv\r\n",
        "    with open(\"snli_1.0_dev.txt\",\"r\") as data:\r\n",
        "        train = csv.DictReader(data, delimiter='\\t')\r\n",
        "        evi_sentences = []\r\n",
        "        hyp_sentences = []\r\n",
        "        labels = []\r\n",
        "        scores = []\r\n",
        "        for row in train:\r\n",
        "            hyp_sentences.append(np.vstack(\r\n",
        "                    sentence2sequence(row[\"sentence1\"].lower())[0]))\r\n",
        "            evi_sentences.append(np.vstack(\r\n",
        "                    sentence2sequence(row[\"sentence2\"].lower())[0]))\r\n",
        "            labels.append(row[\"gold_label\"])\r\n",
        "            scores.append(score_setup(row))\r\n",
        "        \r\n",
        "        hyp_sentences = np.stack([fit_to_size(x, (max_hypothesis_length, vector_size))\r\n",
        "                          for x in hyp_sentences])\r\n",
        "        evi_sentences = np.stack([fit_to_size(x, (max_evidence_length, vector_size))\r\n",
        "                          for x in evi_sentences])\r\n",
        "                                 \r\n",
        "        return (hyp_sentences, evi_sentences), labels, np.array(scores)\r\n",
        "    \r\n",
        "data_feature_list, correct_values, correct_scores = split_data_into_scores()\r\n",
        "\r\n",
        "l_h, l_e = max_hypothesis_length, max_evidence_length\r\n",
        "N, D, H = batch_size, vector_size, hidden_size\r\n",
        "l_seq = l_h + l_e"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIqJr4SH75Sd"
      },
      "source": [
        "#tf.reset_default_graph()\r\n",
        "tf.compat.v1.reset_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI7iVUgo75Xy",
        "outputId": "c5b0c511-60f2-4593-be82-b0e340fb70b5"
      },
      "source": [
        "lstm = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(lstm_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNUmSsEd8CVX"
      },
      "source": [
        "lstm_drop =  tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm, input_p, output_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNQ6-oI78CzF",
        "outputId": "db131b25-28b3-433a-c950-ae6dc6546d21"
      },
      "source": [
        "tf.compat.v1.reset_default_graph()\r\n",
        "lstm = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(lstm_size)\r\n",
        "lstm_drop =  tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm, input_p, output_p)\r\n",
        "# N: The number of elements in each of our batches, \r\n",
        "#   which we use to train subsets of data for efficiency's sake.\r\n",
        "# l_h: The maximum length of a hypothesis, or the second sentence.  This is\r\n",
        "#   used because training an RNN is extraordinarily difficult without \r\n",
        "#   rolling it out to a fixed length.\r\n",
        "# l_e: The maximum length of evidence, the first sentence.  This is used\r\n",
        "#   because training an RNN is extraordinarily difficult without \r\n",
        "#   rolling it out to a fixed length.\r\n",
        "# D: The size of our used GloVe or other vectors.\r\n",
        "tf.compat.v1.disable_eager_execution()\r\n",
        "hyp = tf.compat.v1.placeholder(tf.float32, [N, l_h, D], 'hypothesis')\r\n",
        "evi = tf.compat.v1.placeholder(tf.float32, [N, l_e, D], 'evidence')\r\n",
        "y = tf.compat.v1.placeholder(tf.float32, [N, 3], 'label')\r\n",
        "# hyp: Where the hypotheses will be stored during training.\r\n",
        "# evi: Where the evidences will be stored during training.\r\n",
        "# y: Where correct scores will be stored during training.\r\n",
        "\r\n",
        "# lstm_size: the size of the gates in the LSTM, \r\n",
        "#    as in the first LSTM layer's initialization.\r\n",
        "lstm_back = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(lstm_size)\r\n",
        "# lstm_back:  The LSTM used for looking backwards \r\n",
        "#   through the sentences, similar to lstm.\r\n",
        "\r\n",
        "# input_p: the probability that inputs to the LSTM will be retained at each\r\n",
        "#   iteration of dropout.\r\n",
        "# output_p: the probability that outputs from the LSTM will be retained at \r\n",
        "#   each iteration of dropout.\r\n",
        "lstm_drop_back = tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm_back, input_p, output_p)\r\n",
        "# lstm_drop_back:  A dropout wrapper for lstm_back, like lstm_drop.\r\n",
        "\r\n",
        "\r\n",
        "fc_initializer = tf.random_normal_initializer(stddev=0.1) \r\n",
        "# fc_initializer: initial values for the fully connected layer's weights.\r\n",
        "# hidden_size: the size of the outputs from each lstm layer.  \r\n",
        "#   Multiplied by 2 to account for the two LSTMs.\r\n",
        "fc_weight = tf.compat.v1.get_variable('fc_weight', [2*hidden_size, 3], initializer = fc_initializer)\r\n",
        "# fc_weight: Storage for the fully connected layer's weights.\r\n",
        "fc_bias = tf.compat.v1.get_variable('bias', [3])\r\n",
        "# fc_bias: Storage for the fully connected layer's bias.\r\n",
        "\r\n",
        "# tf.GraphKeys.REGULARIZATION_LOSSES:  A key to a collection in the graph\r\n",
        "#   designated for losses due to regularization.\r\n",
        "#   In this case, this portion of loss is regularization on the weights\r\n",
        "#   for the fully connected layer.\r\n",
        "tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.REGULARIZATION_LOSSES, \r\n",
        "                     tf.nn.l2_loss(fc_weight)) \r\n",
        "\r\n",
        "x = tf.concat([hyp, evi], 1) # N, (Lh+Le), d\r\n",
        "# Permuting batch_size and n_steps\r\n",
        "x = tf.transpose(x, [1, 0, 2]) # (Le+Lh), N, d\r\n",
        "# Reshaping to (n_steps*batch_size, n_input)\r\n",
        "x = tf.reshape(x, [-1, vector_size]) # (Le+Lh)*N, d\r\n",
        "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\r\n",
        "x = tf.split(x, l_seq,)\r\n",
        "\r\n",
        "# x: the inputs to the bidirectional_rnn\r\n",
        "\r\n",
        "\r\n",
        "# tf.contrib.rnn.static_bidirectional_rnn: Runs the input through\r\n",
        "#   two recurrent networks, one that runs the inputs forward and one\r\n",
        "#   that runs the inputs in reversed order, combining the outputs.\r\n",
        "rnn_outputs, _, _ = tf.compat.v1.nn.static_bidirectional_rnn(lstm, lstm_back,\r\n",
        "                                                            x, dtype=tf.float32)\r\n",
        "# rnn_outputs: the list of LSTM outputs, as a list. \r\n",
        "#   What we want is the latest output, rnn_outputs[-1]\r\n",
        "\r\n",
        "classification_scores = tf.matmul(rnn_outputs[-1], fc_weight) + fc_bias\r\n",
        "# The scores are relative certainties for how likely the output matches\r\n",
        "#   a certain entailment: \r\n",
        "#     0: Positive entailment\r\n",
        "#     1: Neutral entailment\r\n",
        "#     2: Negative entailment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-29-41a17d294c7c>:66: static_bidirectional_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:1585: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:753: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSl3ImO28C5W"
      },
      "source": [
        "with tf.compat.v1.variable_scope('Accuracy'):\r\n",
        "    predicts = tf.cast(tf.argmax(classification_scores, 1), 'int32')\r\n",
        "    y_label = tf.cast(tf.argmax(y, 1), 'int32')\r\n",
        "    corrects = tf.equal(predicts, y_label)\r\n",
        "    num_corrects = tf.reduce_sum(tf.cast(corrects, tf.float32))\r\n",
        "    accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\r\n",
        "\r\n",
        "with tf.compat.v1.variable_scope(\"loss\"):\r\n",
        "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\r\n",
        "        logits = classification_scores, labels = y)\r\n",
        "    loss = tf.reduce_mean(cross_entropy)\r\n",
        "    total_loss = loss + weight_decay * tf.add_n(\r\n",
        "        tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.REGULARIZATION_LOSSES))\r\n",
        "\r\n",
        "\r\n",
        "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\r\n",
        "\r\n",
        "opt_op = optimizer.minimize(total_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEcKxm-O8USJ",
        "outputId": "ceea9422-2545-4fef-b8e8-63ea73348bfd"
      },
      "source": [
        "# Initialize variables\r\n",
        "init = tf.compat.v1.global_variables_initializer()\r\n",
        "\r\n",
        "# Use TQDM if installed\r\n",
        "tqdm_installed = False\r\n",
        "try:\r\n",
        "    from tqdm import tqdm\r\n",
        "    tqdm_installed = True\r\n",
        "except:\r\n",
        "    pass\r\n",
        "\r\n",
        "# Launch the Tensorflow session\r\n",
        "sess = tf.compat.v1.Session()\r\n",
        "sess.run(init)\r\n",
        "\r\n",
        "# training_iterations_count: The number of data pieces to train on in total\r\n",
        "# batch_size: The number of data pieces per batch\r\n",
        "training_iterations = range(0,training_iterations_count,batch_size)\r\n",
        "if tqdm_installed:\r\n",
        "    # Add a progress bar if TQDM is installed\r\n",
        "    training_iterations = tqdm(training_iterations)\r\n",
        "\r\n",
        "for i in training_iterations:\r\n",
        "\r\n",
        "    # Select indices for a random data subset\r\n",
        "    batch = np.random.randint(data_feature_list[0].shape[0], size=batch_size)\r\n",
        "    \r\n",
        "    # Use the selected subset indices to initialize the graph's \r\n",
        "    #   placeholder values\r\n",
        "    hyps, evis, ys = (data_feature_list[0][batch,:],\r\n",
        "                      data_feature_list[1][batch,:],\r\n",
        "                      correct_scores[batch])\r\n",
        "    \r\n",
        "    # Run the optimization with these initialized values\r\n",
        "    sess.run([opt_op], feed_dict={hyp: hyps, evi: evis, y: ys})\r\n",
        "    # display_step: how often the accuracy and loss should \r\n",
        "    #   be tested and displayed.\r\n",
        "    if (i/batch_size) % display_step == 0:\r\n",
        "        # Calculate batch accuracy\r\n",
        "        acc = sess.run(accuracy, feed_dict={hyp: hyps, evi: evis, y: ys})\r\n",
        "        # Calculate batch loss\r\n",
        "        tmp_loss = sess.run(loss, feed_dict={hyp: hyps, evi: evis, y: ys})\r\n",
        "        # Display results\r\n",
        "        print(\"Iter \" + str(i/batch_size) + \", Minibatch Loss= \" + \\\r\n",
        "              \"{:.6f}\".format(tmp_loss) + \", Training Accuracy= \" + \\\r\n",
        "              \"{:.5f}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 3/782 [00:02<18:43,  1.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 0.0, Minibatch Loss= 1.136975, Training Accuracy= 0.28906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 13/782 [00:02<03:57,  3.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 10.0, Minibatch Loss= 1.083430, Training Accuracy= 0.43750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 23/782 [00:03<01:32,  8.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 20.0, Minibatch Loss= 1.097638, Training Accuracy= 0.36719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 33/782 [00:04<01:06, 11.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 30.0, Minibatch Loss= 1.093487, Training Accuracy= 0.39844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 43/782 [00:05<01:00, 12.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 40.0, Minibatch Loss= 1.085315, Training Accuracy= 0.38281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  7%|▋         | 53/782 [00:06<00:57, 12.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 50.0, Minibatch Loss= 1.093293, Training Accuracy= 0.37500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 63/782 [00:06<00:57, 12.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 60.0, Minibatch Loss= 1.077751, Training Accuracy= 0.41406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  9%|▉         | 73/782 [00:07<00:54, 12.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 70.0, Minibatch Loss= 1.086088, Training Accuracy= 0.39062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 11%|█         | 83/782 [00:08<00:54, 12.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 80.0, Minibatch Loss= 1.091801, Training Accuracy= 0.39844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 93/782 [00:09<00:52, 13.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 90.0, Minibatch Loss= 1.082077, Training Accuracy= 0.39062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 103/782 [00:10<00:54, 12.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 100.0, Minibatch Loss= 1.089592, Training Accuracy= 0.37500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 113/782 [00:10<00:53, 12.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 110.0, Minibatch Loss= 1.081927, Training Accuracy= 0.43750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 123/782 [00:11<00:50, 12.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 120.0, Minibatch Loss= 1.075867, Training Accuracy= 0.44531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 133/782 [00:12<00:49, 13.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 130.0, Minibatch Loss= 1.090205, Training Accuracy= 0.38281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 143/782 [00:13<00:50, 12.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 140.0, Minibatch Loss= 1.074253, Training Accuracy= 0.43750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 153/782 [00:13<00:50, 12.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 150.0, Minibatch Loss= 1.085869, Training Accuracy= 0.40625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██        | 163/782 [00:14<00:47, 13.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 160.0, Minibatch Loss= 1.082695, Training Accuracy= 0.46875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 173/782 [00:15<00:50, 12.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 170.0, Minibatch Loss= 1.074323, Training Accuracy= 0.41406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 183/782 [00:16<00:47, 12.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 180.0, Minibatch Loss= 1.064982, Training Accuracy= 0.44531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 193/782 [00:17<00:46, 12.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 190.0, Minibatch Loss= 1.092553, Training Accuracy= 0.35156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 203/782 [00:17<00:46, 12.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 200.0, Minibatch Loss= 1.072176, Training Accuracy= 0.39844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 213/782 [00:18<00:45, 12.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 210.0, Minibatch Loss= 1.056574, Training Accuracy= 0.49219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 223/782 [00:19<00:43, 12.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 220.0, Minibatch Loss= 1.058067, Training Accuracy= 0.46094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 233/782 [00:20<00:44, 12.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 230.0, Minibatch Loss= 1.079593, Training Accuracy= 0.42188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|███       | 243/782 [00:21<00:42, 12.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 240.0, Minibatch Loss= 1.066616, Training Accuracy= 0.48438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 253/782 [00:21<00:41, 12.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 250.0, Minibatch Loss= 1.126423, Training Accuracy= 0.35156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 34%|███▎      | 263/782 [00:22<00:40, 12.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 260.0, Minibatch Loss= 1.088224, Training Accuracy= 0.42969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 273/782 [00:23<00:39, 12.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 270.0, Minibatch Loss= 1.078143, Training Accuracy= 0.38281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 283/782 [00:24<00:39, 12.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 280.0, Minibatch Loss= 1.049033, Training Accuracy= 0.48438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 293/782 [00:24<00:37, 12.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 290.0, Minibatch Loss= 1.052362, Training Accuracy= 0.42188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39%|███▊      | 303/782 [00:25<00:37, 12.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 300.0, Minibatch Loss= 1.054415, Training Accuracy= 0.50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 313/782 [00:26<00:38, 12.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 310.0, Minibatch Loss= 1.073400, Training Accuracy= 0.39062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 323/782 [00:27<00:34, 13.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 320.0, Minibatch Loss= 1.069999, Training Accuracy= 0.39062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 333/782 [00:27<00:35, 12.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 330.0, Minibatch Loss= 1.039186, Training Accuracy= 0.46094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 343/782 [00:28<00:35, 12.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 340.0, Minibatch Loss= 1.085784, Training Accuracy= 0.35156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 353/782 [00:29<00:32, 13.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 350.0, Minibatch Loss= 1.045801, Training Accuracy= 0.47656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 363/782 [00:30<00:33, 12.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 360.0, Minibatch Loss= 0.999085, Training Accuracy= 0.50781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 373/782 [00:31<00:33, 12.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 370.0, Minibatch Loss= 1.100352, Training Accuracy= 0.38281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 383/782 [00:31<00:34, 11.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 380.0, Minibatch Loss= 1.066147, Training Accuracy= 0.42188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 393/782 [00:32<00:31, 12.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 390.0, Minibatch Loss= 1.050909, Training Accuracy= 0.41406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 403/782 [00:33<00:30, 12.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 400.0, Minibatch Loss= 1.067608, Training Accuracy= 0.47656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 413/782 [00:34<00:31, 11.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 410.0, Minibatch Loss= 1.046247, Training Accuracy= 0.48438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 423/782 [00:35<00:28, 12.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 420.0, Minibatch Loss= 1.055891, Training Accuracy= 0.49219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 433/782 [00:36<00:27, 12.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 430.0, Minibatch Loss= 1.057264, Training Accuracy= 0.43750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 443/782 [00:36<00:26, 12.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 440.0, Minibatch Loss= 1.067769, Training Accuracy= 0.44531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 453/782 [00:37<00:25, 12.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 450.0, Minibatch Loss= 1.075984, Training Accuracy= 0.42188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 463/782 [00:38<00:25, 12.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 460.0, Minibatch Loss= 1.022461, Training Accuracy= 0.50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 473/782 [00:39<00:24, 12.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 470.0, Minibatch Loss= 1.056720, Training Accuracy= 0.41406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 483/782 [00:39<00:23, 12.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 480.0, Minibatch Loss= 1.103891, Training Accuracy= 0.35156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 493/782 [00:40<00:22, 12.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 490.0, Minibatch Loss= 1.062147, Training Accuracy= 0.44531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 503/782 [00:41<00:21, 12.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 500.0, Minibatch Loss= 1.059920, Training Accuracy= 0.43750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 513/782 [00:42<00:21, 12.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 510.0, Minibatch Loss= 1.055288, Training Accuracy= 0.49219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 523/782 [00:43<00:20, 12.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 520.0, Minibatch Loss= 1.047576, Training Accuracy= 0.49219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 533/782 [00:43<00:19, 12.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 530.0, Minibatch Loss= 1.048116, Training Accuracy= 0.46094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 543/782 [00:44<00:19, 12.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 540.0, Minibatch Loss= 1.060154, Training Accuracy= 0.46094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|███████   | 553/782 [00:45<00:20, 11.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 550.0, Minibatch Loss= 1.055510, Training Accuracy= 0.46094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 563/782 [00:46<00:18, 11.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 560.0, Minibatch Loss= 1.072870, Training Accuracy= 0.43750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 573/782 [00:47<00:16, 12.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 570.0, Minibatch Loss= 1.041291, Training Accuracy= 0.43750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 583/782 [00:48<00:15, 12.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 580.0, Minibatch Loss= 1.062024, Training Accuracy= 0.42969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 593/782 [00:48<00:15, 12.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 590.0, Minibatch Loss= 1.017965, Training Accuracy= 0.48438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 603/782 [00:49<00:14, 12.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 600.0, Minibatch Loss= 1.021154, Training Accuracy= 0.51562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 613/782 [00:50<00:14, 11.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 610.0, Minibatch Loss= 1.038147, Training Accuracy= 0.44531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 623/782 [00:51<00:13, 12.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 620.0, Minibatch Loss= 1.056486, Training Accuracy= 0.41406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 633/782 [00:52<00:11, 12.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 630.0, Minibatch Loss= 1.012101, Training Accuracy= 0.53125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 643/782 [00:52<00:11, 11.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 640.0, Minibatch Loss= 1.022638, Training Accuracy= 0.53125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▎ | 653/782 [00:53<00:10, 11.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 650.0, Minibatch Loss= 1.011306, Training Accuracy= 0.54688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 663/782 [00:54<00:10, 11.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 660.0, Minibatch Loss= 1.037687, Training Accuracy= 0.50781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 673/782 [00:55<00:08, 12.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 670.0, Minibatch Loss= 1.040874, Training Accuracy= 0.51562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 683/782 [00:56<00:07, 12.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 680.0, Minibatch Loss= 1.029845, Training Accuracy= 0.46094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89%|████████▊ | 693/782 [00:57<00:07, 12.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 690.0, Minibatch Loss= 1.013664, Training Accuracy= 0.53125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 703/782 [00:57<00:06, 12.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 700.0, Minibatch Loss= 1.033916, Training Accuracy= 0.47656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 713/782 [00:58<00:05, 12.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 710.0, Minibatch Loss= 1.029265, Training Accuracy= 0.51562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 723/782 [00:59<00:04, 12.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 720.0, Minibatch Loss= 1.061692, Training Accuracy= 0.47656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 94%|█████████▎| 733/782 [01:00<00:04, 11.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 730.0, Minibatch Loss= 1.026235, Training Accuracy= 0.46875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 743/782 [01:01<00:03, 12.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 740.0, Minibatch Loss= 1.003820, Training Accuracy= 0.51562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 753/782 [01:01<00:02, 11.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 750.0, Minibatch Loss= 1.062427, Training Accuracy= 0.42188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 763/782 [01:02<00:01, 11.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 760.0, Minibatch Loss= 1.080020, Training Accuracy= 0.42969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 773/782 [01:03<00:00, 11.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 770.0, Minibatch Loss= 1.027566, Training Accuracy= 0.53906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [01:04<00:00, 12.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter 780.0, Minibatch Loss= 0.986779, Training Accuracy= 0.56250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrBjAP_d9bve",
        "outputId": "f7081bcc-1a12-4860-b0ca-b447089ed7e2"
      },
      "source": [
        "evidences = [\"Maurita and Jade both were at the scene of the car crash.\"]\r\n",
        "\r\n",
        "hypotheses = [\"Multiple people saw the accident.\"]\r\n",
        "\r\n",
        "sentence1 = [fit_to_size(np.vstack(sentence2sequence(evidence)[0]),\r\n",
        "                         (30, 50)) for evidence in evidences]\r\n",
        "\r\n",
        "sentence2 = [fit_to_size(np.vstack(sentence2sequence(hypothesis)[0]),\r\n",
        "                         (30,50)) for hypothesis in hypotheses]\r\n",
        "\r\n",
        "prediction = sess.run(classification_scores, feed_dict={hyp: (sentence1 * N),\r\n",
        "                                                        evi: (sentence2 * N),\r\n",
        "                                                        y: [[0,0,0]]*N})\r\n",
        "print([\"Positive\", \"Neutral\", \"Negative\"][np.argmax(prediction[0])]+\r\n",
        "      \" entailment\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Positive entailment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTH5hs6_C0sk",
        "outputId": "5b66a7e9-ef06-41e7-ffd7-2025501b45ea"
      },
      "source": [
        "evidences = [\"I went to the store yesterday.\"]\r\n",
        "\r\n",
        "hypotheses = [\"My dog is nine.\"]\r\n",
        "\r\n",
        "sentence1 = [fit_to_size(np.vstack(sentence2sequence(evidence)[0]),\r\n",
        "                         (30, 50)) for evidence in evidences]\r\n",
        "\r\n",
        "sentence2 = [fit_to_size(np.vstack(sentence2sequence(hypothesis)[0]),\r\n",
        "                         (30,50)) for hypothesis in hypotheses]\r\n",
        "\r\n",
        "prediction = sess.run(classification_scores, feed_dict={hyp: (sentence1 * N),\r\n",
        "                                                        evi: (sentence2 * N),\r\n",
        "                                                        y: [[0,0,0]]*N})\r\n",
        "print([\"Positive\", \"Neutral\", \"Negative\"][np.argmax(prediction[0])]+\r\n",
        "      \" entailment\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive entailment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avgfyDDq9cb3"
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}